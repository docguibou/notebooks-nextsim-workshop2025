{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f851a91-3cc8-4df7-9d03-d4930004391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "notebook_root = \"/home/notebooks-nextsim-workshop2025/\"\n",
    "data_root = \"/home/data-nextsim-workshop2025/\"\n",
    "sys.path.append(os.path.join(data_root, 'assimilation', 'NEDAS'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8eeb6-d888-4af2-be26-e79039acd378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from netCDF4 import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84839508-9cd0-4c7d-89aa-d882689d78c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NEDAS\n",
    "from NEDAS.utils.netcdf_lib import nc_write_var, nc_read_var\n",
    "from NEDAS.models.nextsim.dg import NextsimDGModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a39315-076a-4a63-aa16-5f2b700ce925",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NextsimDGModel(config_file=os.path.join(notebook_root, \"assimilation\", \"nextsim-config.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4381c97c-dc78-47f3-b5d6-b134b5c8ef25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid from june23 case\n",
    "infile = os.path.join(data_root, 'nextsimdg', 'demo-realistic', 'init_25km_NH.nc')\n",
    "with Dataset(infile, 'r') as f:\n",
    "    lon = f['data/longitude'][:]\n",
    "    lat = f['data/latitude'][:]\n",
    "x1, y1 = model.grid.proj(lon, lat)\n",
    "grid = NEDAS.grid.Grid(model.grid.proj, x1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db097dc-114b-4da0-bf92-6878be2cac0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new grid\n",
    "dx = 50000.\n",
    "x, y = np.meshgrid(np.arange(-2270000., 1395000., dx), np.arange(-850000., 2020000., dx))\n",
    "xv, yv = np.meshgrid(np.arange(-2270000.-dx/2, 1395000.+dx/2, dx), np.arange(-850000.-dx/2, 2020000.+dx/2, dx))\n",
    "newgrid = NEDAS.grid.Grid(model.grid.proj, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0187f036-f3ae-4ab2-8d11-e2368c6863af",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.x.shape, newgrid.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce283ac-6af6-49cb-8d39-f4caebbc1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_group(src_group, dst_group):\n",
    "    # Copy attributes\n",
    "    for attr in src_group.ncattrs():\n",
    "        dst_group.setncattr(attr, src_group.getncattr(attr))\n",
    "\n",
    "    # Copy dimensions (skip if already defined)\n",
    "    for dim_name, dim in src_group.dimensions.items():\n",
    "        if dim_name not in dst_group.dimensions:\n",
    "            dst_group.createDimension(dim_name, None if dim.isunlimited() else len(dim))\n",
    "\n",
    "    # Copy variables\n",
    "    for var_name, var in src_group.variables.items():\n",
    "        dst_var = dst_group.createVariable(var_name, var.datatype, var.dimensions)\n",
    "        dst_var.setncatts({k: var.getncattr(k) for k in var.ncattrs()})\n",
    "\n",
    "        if var.ndim == 0:\n",
    "            dst_var[()] = var[()]\n",
    "        else:\n",
    "            dst_var[:] = var[:]\n",
    "    \n",
    "    # Recursively copy sub-groups\n",
    "    for subgrp_name, subgrp in src_group.groups.items():\n",
    "        dst_subgrp = dst_group.createGroup(subgrp_name)\n",
    "        copy_group(subgrp, dst_subgrp)\n",
    "\n",
    "def downscale_forcing(infile, outfile, grid, t_ind, x, y):\n",
    "    os.system(\"rm \"+outfile)\n",
    "    src = Dataset(infile, 'r')\n",
    "    dst = Dataset(outfile, 'w')\n",
    "\n",
    "    copy_group(src.groups[\"structure\"], dst.createGroup(\"structure\"))\n",
    "    copy_group(src.groups[\"metadata\"], dst.createGroup(\"metadata\"))\n",
    "\n",
    "    newgrid = NEDAS.grid.Grid(grid.proj, x, y)\n",
    "    grid.set_destination_grid(newgrid)\n",
    "\n",
    "    nt = len(t_ind)\n",
    "    ny, nx = newgrid.x.shape\n",
    "\n",
    "    grp = dst.createGroup('data')\n",
    "    grp.createDimension('time', None)\n",
    "    grp.createDimension('x', nx)\n",
    "    grp.createDimension('y', ny)\n",
    "    \n",
    "    for var_name, var in src.groups['data'].variables.items():\n",
    "        print(var_name, var.shape)\n",
    "        if var_name == 'time':\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"time\",))\n",
    "            newvar[:] = var[t_ind]\n",
    "        elif var_name in ['longitude', 'latitude']:\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"y\", \"x\"))\n",
    "            newvar[:] = grid.convert(var[:])\n",
    "        else:\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"time\", \"y\", \"x\"))\n",
    "            fld = np.zeros((nt, ny, nx))\n",
    "            for n in range(nt):\n",
    "                srcfld = var[t_ind[n],:,:].data\n",
    "                srcmask = var[t_ind[n],:,:].mask\n",
    "                srcfld[srcmask] = np.nan\n",
    "                fld[n,:,:] = grid.convert(srcfld)\n",
    "            newvar[:] = fld\n",
    "\n",
    "    src.close()\n",
    "    dst.close()\n",
    "\n",
    "def downscale_restart(infile, outfile, grid, x, y, xv, yv):\n",
    "    os.system(\"rm \"+outfile)\n",
    "    src = Dataset(infile, 'r')\n",
    "    dst = Dataset(outfile, 'w')\n",
    "\n",
    "    copy_group(src.groups[\"structure\"], dst.createGroup(\"structure\"))\n",
    "    copy_group(src.groups[\"metadata\"], dst.createGroup(\"metadata\"))\n",
    "\n",
    "    newgrid = NEDAS.grid.Grid(grid.proj, x, y)\n",
    "    grid.set_destination_grid(newgrid)\n",
    "    ny, nx = newgrid.x.shape\n",
    "\n",
    "    grp = dst.createGroup('data')\n",
    "    grp.createDimension('time', None)\n",
    "    grp.createDimension('z', 3)\n",
    "    grp.createDimension('x', nx)\n",
    "    grp.createDimension('y', ny)\n",
    "    grp.createDimension('xvertex', nx+1)\n",
    "    grp.createDimension('yvertex', ny+1)\n",
    "    grp.createDimension('x_cg', nx+1)\n",
    "    grp.createDimension('y_cg', ny+1)\n",
    "    grp.createDimension('dg_comp', 1)\n",
    "    grp.createDimension('dgstress_comp', 3)\n",
    "    grp.createDimension('ncoords', 2)\n",
    "    \n",
    "    for var_name, var in src.groups['data'].variables.items():\n",
    "        print(var_name, var.shape)\n",
    "        if var_name == 'coords':\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"yvertex\",\"xvertex\",\"ncoords\"))\n",
    "            coords = np.zeros((ny+1, nx+1, 2))\n",
    "            coords[:,:,0],coords[:,:,1] = grid.proj(xv, yv, inverse=True)\n",
    "            newvar[:] = coords\n",
    "        elif var_name == 'tice':\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"z\", \"y\", \"x\"))\n",
    "            fld = np.zeros((3, ny, nx))\n",
    "            for i in range(3):\n",
    "                srcfld = var[i,:,:].data\n",
    "                srcmask = var[i,:,:].mask\n",
    "                srcfld[srcmask] = np.nan\n",
    "                fld[i,:,:] = grid.convert(srcfld)\n",
    "            newvar[:] = fld\n",
    "        elif var_name == 'mask':\n",
    "            pass\n",
    "        else:\n",
    "            newvar = grp.createVariable(var_name, \"f8\", (\"y\", \"x\"))\n",
    "            srcfld = var[:,:].data\n",
    "            srcmask = var[:,:].mask\n",
    "            srcfld[srcmask] = np.nan\n",
    "            fld = grid.convert(srcfld)\n",
    "            newvar[:] = fld\n",
    "            if var_name == 'cice':\n",
    "                ##save a mask for later\n",
    "                mask = np.isnan(fld)\n",
    "    \n",
    "    newvar = grp.createVariable('mask', \"f8\", (\"y\", \"x\"))\n",
    "    fld = np.ones((ny, nx))\n",
    "    fld[mask] = 0\n",
    "    newvar[:] = fld\n",
    "    \n",
    "    src.close()\n",
    "    dst.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65217918-a185-40c2-9956-bd00e1c7996b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset time steps\n",
    "n_days = 5   #number of days\n",
    "d_hours = 6  #interval in hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290ad582-dfbf-472f-8bcf-cfe020ddddad",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = os.path.join(data_root, 'nextsimdg', 'demo-realistic', '25km_NH.ERA5_2010-01-01_2010-01-10.nc')\n",
    "outfile = os.path.join(data_root, 'assimilation', 'icbc', '25km_NH.ERA5.nc')\n",
    "t_ind = np.arange(0, 24*n_days, d_hours)\n",
    "downscale_forcing(infile, outfile, grid, t_ind, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5798271-63b1-482c-bb22-a87ea6b0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = os.path.join(data_root, 'nextsimdg', 'demo-realistic', '25km_NH.TOPAZ4_2010-01-01_2010-01-10.nc')\n",
    "outfile = os.path.join(data_root, 'assimilation', 'icbc', '25km_NH.TOPAZ4.nc')\n",
    "t_ind = np.arange(0, n_days)\n",
    "downscale_forcing(infile, outfile, grid, t_ind, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de07468-26ea-40fe-ac1d-6203c753534f",
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = os.path.join(data_root, 'nextsimdg', 'demo-realistic', 'init_25km_NH.nc')\n",
    "outfile = os.path.join(data_root, 'assimilation', 'icbc', 'restart2010-01-01T00:00:00Z.nc')\n",
    "downscale_restart(infile, outfile, grid, x, y, xv, yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9fec70-3789-453e-8b9e-b39022f55af9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
